{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5bc4c2c-4d91-4c0a-a1ae-f7b529133359",
   "metadata": {},
   "source": [
    "**Using Brev.dev's single A10G with 24GB GPU Memory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a7971dc-38a8-4ea7-9fe6-5d4ccb8ea6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# You only need to run this once per machine\n",
    "!pip install -q -U bitsandbytes\n",
    "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
    "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
    "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
    "!pip install -q -U datasets scipy ipywidgets matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb4e7bba-1568-480f-9994-243d9f2e86d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "train_dataset = load_dataset('json', data_files='notes.jsonl', split='train')\n",
    "eval_dataset = load_dataset('json', data_files='notes_validation.jsonl', split='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f0fa52-afac-4c4c-88aa-08757e30bab1",
   "metadata": {},
   "source": [
    "**Training Metrics**: using Weights & Biases to keep track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78f1c78a-e5ef-4f85-899d-6a3f394efeba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbriebi\u001b[0m (\u001b[33mbriebi-university-of-michigan\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "!pip install -q wandb -U\n",
    "\n",
    "import wandb, os\n",
    "wandb.login()\n",
    "\n",
    "wandb_project = \"journal-finetune\"\n",
    "if len(wandb_project) > 0:\n",
    "    os.environ[\"WANDB_PROJECT\"] = wandb_project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8889df7b-70c7-46fd-9761-712a2473b9ac",
   "metadata": {},
   "source": [
    "**Formatting Function**: structures training examples into prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a0b733e-bdfc-4ee7-899d-69945fe640d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_func(example):\n",
    "    text = f\"### Question: {example['input']}\\n ### Answer: {example['output']}\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded4aa60-f685-4ea5-85ac-9366273da74f",
   "metadata": {},
   "source": [
    "**Loading Mistral** - mistralai/Mistral-7B-v0.1 - using 4-bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d85db17-407a-4258-87f7-d99da4f4494a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fb919b3775648cb91b5c045b5440cef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07075824-3de8-4b4a-af5b-b80f41a8fcc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73418e8914bd4e30ad82b72023220195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "base_model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe5937e-1244-4363-aa41-4dd8562fbd26",
   "metadata": {},
   "source": [
    "**Tokenization**: setting up tokenizer and adding left padding (training uses less memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2067a78-358b-489d-8ddd-608c1e95506e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    padding_side=\"left\",\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def generate_and_tokenize_prompt(prompt):\n",
    "    return tokenizer(formatting_func(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b94d0b4-8beb-4a59-ab1c-7a214c8690f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt)\n",
    "tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca4cecc-d48e-4596-8ead-2174fa849187",
   "metadata": {},
   "source": [
    "**Distribution Plot**: helps to determine max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f73422e-8a57-491e-9c2f-b0ae29ad891e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset):\n",
    "    lengths = [len(x['input_ids']) for x in tokenized_train_dataset]\n",
    "    lengths += [len(x['input_ids']) for x in tokenized_val_dataset]\n",
    "    print(len(lengths))\n",
    "\n",
    "    # Plotting the histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(lengths, bins=20, alpha=0.7, color='blue')\n",
    "    plt.xlabel('Length of input_ids')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Lengths of input_ids')\n",
    "    plt.show()\n",
    "\n",
    "plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1014d8d-02ee-4e48-a23f-5a27e57aefa9",
   "metadata": {},
   "source": [
    "**Padding**: adding padding so that all prompts are same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61c92573-01c8-4f4e-b385-f957c7bdcd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 105 # This was an appropriate max length for my dataset\n",
    "\n",
    "def generate_and_tokenize_prompt2(prompt):\n",
    "    result = tokenizer(\n",
    "        formatting_func(prompt),\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b289416e-9fa6-49c0-a5a3-d4942939ed9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83b4c28c348d4184991cbe3363bc50f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/31 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt2)\n",
    "tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "440d760d-4d9c-4bd4-8363-d43224c443bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 774, 22478, 28747, 1824, 863, 4417, 17577, 4555, 511, 28804, 13, 774, 26307, 28747, 650, 15577, 1360, 298, 7674, 272, 1419, 697, 302, 16872, 1063, 28723, 650, 7761, 736, 460, 264, 4997, 5185, 369, 460, 12598, 298, 347, 1132, 369, 541, 16205, 272, 1419, 697, 302, 16872, 1063, 28723, 2]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_train_dataset[1]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "202746d2-96d6-43e7-8bab-21d11ac970c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb013228-10c7-4cf6-b1c0-0efb6be78541",
   "metadata": {},
   "source": [
    "**Testing Base Model**: using a simple prompt to see what the base model would output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e76ef05-75ee-446a-85a5-79cbd6bfa401",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_prompt = \" What is AI? \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ed57e75-235c-4f1d-ab0a-49f176069d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is AI?  Artificial Intelligence (AI) is a branch of computer science that deals with the simulation of intelligent behavior in computers.\n",
      "\n",
      "What are some examples of AI?  Some examples include:\n",
      "\n",
      "- Self driving cars\n",
      "- Robots\n",
      "- Chatbots\n",
      "- Virtual assistants\n",
      "- Smart home devices\n",
      "- Fraud detection systems\n",
      "- Medical diagnosis and treatment planning\n",
      "- Recommendation engines\n",
      "- Personalized advertising\n",
      "- Predictive maintenance\n",
      "- Natural language processing\n",
      "- Image recognition\n",
      "- Speech recognition\n",
      "- Machine learning\n",
      "- Data mining\n",
      "- Expert systems\n",
      "- Game playing programs\n",
      "- Planning and scheduling systems\n",
      "- Knowledge representation and reasoning\n",
      "- Computer vision\n",
      "- Robotics\n",
      "- Natural language generation\n",
      "- Automated theorem proving\n",
      "- Expert systems\n",
      "- Intelligent tutoring systems\n",
      "- Decision support systems\n",
      "- Constraint satisfaction problems\n",
      "- Multiagent systems\n",
      "- Evolutionary computation\n",
      "- Fuzzy logic\n",
      "- Neural networks\n",
      "- Genetic algorithms\n",
      "- Swarm intelligence\n",
      "- Reinforcement learning\n",
      "- Bayesian networks\n",
      "- Distributed artificial intelligence\n",
      "- Hybrid intelligent systems\n",
      "- Cognitive robotics\n",
      "- Affective computing\n",
      "- Amb\n"
     ]
    }
   ],
   "source": [
    "# Init an eval tokenizer that doesn't add padding or eos token\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(model.generate(**model_input, max_new_tokens=256, repetition_penalty=1.15)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af9f66f-9551-4e85-91dd-bf4698f9891f",
   "metadata": {},
   "source": [
    "**Preprocessing**: done before setting up LoRA to prepare it for finetuning, done using kit from PEFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d54d70f9-0e90-4a5f-9e35-5ce537998861",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00e1e91a-c73b-4a1f-a6cf-a67f10ca8273",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ff8f95-e20d-476e-8a58-6ac92b695523",
   "metadata": {},
   "source": [
    "**Printing Model**: the linear layers that QLoRA will be applied to (q_proj, k_proj, v_proj, o_proj, gate_proj, up_proj, down_proj, and lm_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d0ccac7-7274-4fde-8b87-6527260fefac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MistralForCausalLM(\n",
      "  (model): MistralModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x MistralDecoderLayer(\n",
      "        (self_attn): MistralSdpaAttention(\n",
      "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): MistralRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): MistralMLP(\n",
      "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
      "        (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
      "      )\n",
      "    )\n",
      "    (norm): MistralRMSNorm((4096,), eps=1e-05)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6c0a2c-d566-464a-9c37-7a40fa3c90d4",
   "metadata": {},
   "source": [
    "**LoRA Config**: \n",
    "\n",
    "`r`: rank of the low-rank matrix used in the adapters, which controls number of parameters trained\n",
    "\n",
    "`alpha`: scaling factor for the learned weights; the weight matrix is scaled by `alpha/r`\n",
    "\n",
    "Using `r=32` and `lora_alpha=64` so that we have more emphasis on the new fine-tuned data while also reducing computational complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "83c6f4c3-9659-4f4e-9a72-c4dae89cfabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 85041152 || all params: 3837112320 || trainable%: 2.2162799758751914\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=64,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "        \"lm_head\",\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    lora_dropout=0.05,  # Conventional\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3f673cf4-b3e2-4bd8-a456-d3e3cff5531b",
   "metadata": {},
   "source": [
    "**See New LoRA adaptors!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a7cea56-d9fc-4394-8f11-0dba70526a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): MistralForCausalLM(\n",
      "      (model): MistralModel(\n",
      "        (embed_tokens): Embedding(32000, 4096)\n",
      "        (layers): ModuleList(\n",
      "          (0-31): 32 x MistralDecoderLayer(\n",
      "            (self_attn): MistralSdpaAttention(\n",
      "              (q_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (k_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (v_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (o_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (rotary_emb): MistralRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): MistralMLP(\n",
      "              (gate_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=14336, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (up_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=14336, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (down_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=14336, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "            (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
      "            (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (norm): MistralRMSNorm((4096,), eps=1e-05)\n",
      "      )\n",
      "      (lm_head): lora.Linear(\n",
      "        (base_layer): Linear(in_features=4096, out_features=32000, bias=False)\n",
      "        (lora_dropout): ModuleDict(\n",
      "          (default): Dropout(p=0.05, inplace=False)\n",
      "        )\n",
      "        (lora_A): ModuleDict(\n",
      "          (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "        )\n",
      "        (lora_B): ModuleDict(\n",
      "          (default): Linear(in_features=32, out_features=32000, bias=False)\n",
      "        )\n",
      "        (lora_embedding_A): ParameterDict()\n",
      "        (lora_embedding_B): ParameterDict()\n",
      "        (lora_magnitude_vector): ModuleDict()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5876cd2-2998-4ec6-87fb-3b881147a614",
   "metadata": {},
   "source": [
    "**Running Training**: used 'max_steps' = 500, because I did not mind overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "13154cf1-5ca6-4e31-b9e5-7c3e0e7209ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 1: # If more than 1 GPU\n",
    "    model.is_parallelizable = True\n",
    "    model.model_parallel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d370556f-6609-47fc-b4eb-3ad32d108cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "model = accelerator.prepare_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b110ad8e-a4b8-4112-ba0d-0631fe756e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/verb-workspace/wandb/run-20240806_211458-jiwschqc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/briebi-university-of-michigan/journal-finetune/runs/jiwschqc' target=\"_blank\">mistral-journal-finetune-2024-08-06-21-14</a></strong> to <a href='https://wandb.ai/briebi-university-of-michigan/journal-finetune' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/briebi-university-of-michigan/journal-finetune' target=\"_blank\">https://wandb.ai/briebi-university-of-michigan/journal-finetune</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/briebi-university-of-michigan/journal-finetune/runs/jiwschqc' target=\"_blank\">https://wandb.ai/briebi-university-of-michigan/journal-finetune/runs/jiwschqc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 07:49, Epoch 8/9]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.363200</td>\n",
       "      <td>1.411525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.046800</td>\n",
       "      <td>1.314340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.654600</td>\n",
       "      <td>1.187133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.304300</td>\n",
       "      <td>1.258486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>1.249200</td>\n",
       "      <td>1.310352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.701600</td>\n",
       "      <td>1.457755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.739900</td>\n",
       "      <td>1.408645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.474800</td>\n",
       "      <td>1.933361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.332500</td>\n",
       "      <td>1.708018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.329900</td>\n",
       "      <td>1.753429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.239700</td>\n",
       "      <td>1.979452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.224000</td>\n",
       "      <td>1.807280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.181000</td>\n",
       "      <td>2.050468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.168600</td>\n",
       "      <td>1.977072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.174300</td>\n",
       "      <td>1.978386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.137000</td>\n",
       "      <td>2.113593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.142100</td>\n",
       "      <td>2.204940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.134700</td>\n",
       "      <td>2.291397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>2.320555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.132100</td>\n",
       "      <td>2.330811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:203: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:203: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:203: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:203: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:203: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:203: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:203: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:203: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:203: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:203: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:203: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:203: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:203: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:203: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:203: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:203: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:203: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:203: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:203: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:203: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=500, training_loss=0.6430302786827088, metrics={'train_runtime': 471.294, 'train_samples_per_second': 2.122, 'train_steps_per_second': 1.061, 'total_flos': 4533291786240000.0, 'train_loss': 0.6430302786827088, 'epoch': 8.064516129032258})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "from datetime import datetime\n",
    "\n",
    "project = \"journal-finetune\"\n",
    "base_model_name = \"mistral\"\n",
    "run_name = base_model_name + \"-\" + project\n",
    "output_dir = \"./\" + run_name\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    "    args=transformers.TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        warmup_steps=2,\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=1,\n",
    "        gradient_checkpointing=True,\n",
    "        max_steps=500,\n",
    "        learning_rate=2.5e-5, \n",
    "        bf16=True,\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        logging_steps=25,              \n",
    "        logging_dir=\"./logs\",        \n",
    "        save_strategy=\"steps\",       \n",
    "        save_steps=25,                \n",
    "        evaluation_strategy=\"steps\", \n",
    "        eval_steps=25,               \n",
    "        do_eval=True,                \n",
    "        report_to=\"wandb\",           \n",
    "        run_name=f\"{run_name}-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\"          \n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "\n",
    "model.config.use_cache = False  \n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe51db5e-0d46-44ec-840b-2462a91e1ca9",
   "metadata": {},
   "source": [
    "**Trained Model**: used checkpoint-125; need to reload base model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e5ca1d0b-a0a4-4e9b-8610-d53e577aed4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e23a27ab66449d29755686720636258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "base_model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,  # Mistral, same as before\n",
    "    quantization_config=bnb_config,  # Same quantization config as before\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_bos_token=True, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6458a67d-d179-41a3-8788-26cd93f378bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "ft_model = PeftModel.from_pretrained(base_model, \"mistral-journal-finetune/checkpoint-125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1b2a3874-4e62-401e-a8d7-5e1376c3cb2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How does direction of fit apply to social media?  In other words, how do AI and ML affect the way we think about direction of fit in terms of social media?\n",
      " ### Answer: AI and ML are used to manipulate peopleâ€™s behavior on social media. For example, Facebook uses algorithms that show you content that keeps you engaged for longer periods of time. This is an example of direction of fit because it changes your behavior to fit its goals (keeping you on the platform).\n",
      "How does direction of fit apply to autonomous weapons?\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = \" How does direction of fit apply to social media? \"\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=100, repetition_penalty=1.15)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b016dd-8d22-461e-bdd7-e81db23f2dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
