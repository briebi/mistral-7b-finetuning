{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4142fecd-fd3e-4197-820d-332554a7c5b4",
   "metadata": {},
   "source": [
    "**Using Brev.dev's single A10G with 24GB GPU Memory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "845eb766-52af-4c46-b587-8eba79582008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -U bitsandbytes\n",
    "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
    "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
    "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
    "!pip install -q -U datasets scipy ipywidgets matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96901c94-055b-4545-b2af-9f89dfc301c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (23.0.1)\n",
      "Collecting pip\n",
      "  Downloading pip-24.2-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 23.0.1\n",
      "    Uninstalling pip-23.0.1:\n",
      "      Successfully uninstalled pip-23.0.1\n",
      "Successfully installed pip-24.2\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6f6e14f-b1ee-4463-a81e-c54de2346545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf9ac048809442c18f6b855dc5ddffe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c7f2f2001f64685a0de0ec3327f398c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "train_dataset = load_dataset('json', data_files='notes.jsonl', split='train')\n",
    "eval_dataset = load_dataset('json', data_files='notes_validation.jsonl', split='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e45f295-0623-4c0b-8e41-de8c0b4f8165",
   "metadata": {},
   "source": [
    "**Training Metrics**: using Weights & Biases to keep track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83ec803c-f931-4f1e-9ec1-93d6d93e3e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/ubuntu/.netrc\n"
     ]
    }
   ],
   "source": [
    "!pip install -q wandb -U\n",
    "\n",
    "import wandb, os\n",
    "wandb.login()\n",
    "\n",
    "wandb_project = \"journal-finetune\"\n",
    "if len(wandb_project) > 0:\n",
    "    os.environ[\"WANDB_PROJECT\"] = wandb_project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a236df-d939-4533-86ad-b0c644a3a10e",
   "metadata": {},
   "source": [
    "**Formatting Function**: structures training examples into prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0ebf15b-5392-447d-b187-9c3192ea8162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_func(example):\n",
    "    text = f\"### Question: {example['input']}\\n ### Answer: {example['output']}\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baf05c6-3622-447c-bf0b-5b7d64f11c27",
   "metadata": {},
   "source": [
    "**Loading Mistral** - mistralai/Mistral-7B-v0.1 - using 4-bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74a31b1f-54d8-42b6-85a0-596478fd7fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49e19422ff3c4082bd118deaeecf169d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e261be98-51c9-4a4e-a571-ba00895df0f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e71d143af1534a2f973bc4acd5c04fef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "224b26dc5d414d81afb312f8cf0c48f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99a73100161b40e58ada812cbf5eb905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bde4421a898b41f9a27865d96976d27c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78a6d157d592484abd794de4560c6d2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fd88aae8ada4030a0cd70923672bd64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef224bfdb9374648b1cb5816bb549493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "base_model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f2b3e3-5169-4d57-bdf2-c40ff0163f30",
   "metadata": {},
   "source": [
    "**Tokenization**: setting up tokenizer and adding left padding (training uses less memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7a4c560-7d00-401c-ac40-762eff883a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be35c9b6fa3b4cc3b1f2f0a23daa45ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/996 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "767a6ff6313b472d804d89d27ecab5db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ac27c27fb874bcaa924319aac5ac99b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9998f6d2e191468cb5be37ea5fb26f1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    padding_side=\"left\",\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def generate_and_tokenize_prompt(prompt):\n",
    "    return tokenizer(formatting_func(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "816ab359-6b50-4b6f-b7fa-75f0e9b10265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75f41537f0484c57828cffc817d7fb75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/124 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fec2395748874c4cab137d6e65b1be08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/31 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt)\n",
    "tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c51f006-656a-4f13-8e21-9fb18680c0c3",
   "metadata": {},
   "source": [
    "**Distribution Plot**: helps to determine max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "831a9098-7d60-45d1-9d05-77badb88215d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset):\n",
    "    lengths = [len(x['input_ids']) for x in tokenized_train_dataset]\n",
    "    lengths += [len(x['input_ids']) for x in tokenized_val_dataset]\n",
    "    print(len(lengths))\n",
    "\n",
    "    # Plotting the histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(lengths, bins=20, alpha=0.7, color='blue')\n",
    "    plt.xlabel('Length of input_ids')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Lengths of input_ids')\n",
    "    plt.show()\n",
    "\n",
    "plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e28d72-31bd-4267-bf23-90fad4df7393",
   "metadata": {},
   "source": [
    "**Padding**: adding padding so that all prompts are same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1b3c7e3-9566-4fa1-b6cf-ab3004f2914f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 105 # This was an appropriate max length for my dataset\n",
    "\n",
    "def generate_and_tokenize_prompt2(prompt):\n",
    "    result = tokenizer(\n",
    "        formatting_func(prompt),\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c5c55eb-af8f-4d90-9cca-8b65daacb99c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beba13d9ff7744a2b1f6ea629b1f09cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/124 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ce150033e7479aa65cafbd9439d266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/31 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt2)\n",
    "tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e8e3e5b-b159-427f-a6bb-84b4946193a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 774, 22478, 28747, 1824, 863, 4417, 17577, 4555, 511, 28804, 13, 774, 26307, 28747, 650, 15577, 1360, 298, 7674, 272, 1419, 697, 302, 16872, 1063, 28723, 650, 7761, 736, 460, 264, 4997, 5185, 369, 460, 12598, 298, 347, 1132, 369, 541, 16205, 272, 1419, 697, 302, 16872, 1063, 28723, 2]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_train_dataset[1]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e7103d1-0923-45c0-9876-7204225f36d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4bda3b2-74f4-42ad-9d00-e43775537cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_prompt = \" How does direction of fit apply to social media? \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1d23f3a-0781-4396-b3c7-4e90dbe80d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How does direction of fit apply to social media?  It’s a question I get asked often.\n",
      "\n",
      "The answer is simple: it doesn’t.\n",
      "\n",
      "Direction of fit applies to the relationship between theory and evidence, not between people and technology.\n",
      "\n",
      "In this post, I will explain why direction of fit is irrelevant for social media.\n",
      "\n",
      "## What is Direction of Fit?\n",
      "\n",
      "Direction of fit was first introduced by philosopher David Lewis in his book Convention (1969). In that work, he distinguishes two types of conventions:\n",
      "\n",
      "- Conventions of use: these are conventions where the meaning of an expression depends on its use. For example, when we say “I am going to the movies”, we mean that we are going to watch a movie at the cinema. The meaning of our statement depends on how we use it. If we were to go to the movies with a friend who has never been to the cinema before, then we would have to explain what we meant by saying “movies”.\n",
      "- Conventions of design: these are conventions where the meaning of an expression does not depend on its use. For example, when we say “the sky is blue”, we mean that the sky is blue. The meaning of our statement does\n"
     ]
    }
   ],
   "source": [
    "eval_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(model.generate(**model_input, max_new_tokens=256, repetition_penalty=1.15)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4d6dfce-a29d-492e-95b3-a5a0ac205cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_prompt = \" What are the differences between Gramsci's and Plato's beliefs about reality? \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2b01d9c-0a4c-458d-88b2-7be671736fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the differences between Gramsci's and Plato's beliefs about reality? 1. Both believe that there is a reality beyond what we perceive with our senses, but they differ in how they define this reality. For Plato, reality is made up of ideal forms or essences that exist independently of human perception. These forms are perfect and unchanging, and they serve as models for all physical objects in the world. For Gramsci, on the other hand, reality is not composed of fixed entities but rather is constantly changing and evolving. He believes that reality is shaped by social forces such as power relations and ideology, which can distort our understanding of the world around us.\n",
      "\n",
      "2. Plato sees the world as divided into two realms: the realm of ideas (or Forms) and the realm of appearances (or phenomena). The former is the true reality, while the latter is merely an imperfect reflection of it. In contrast, Gramsci does not make such a sharp distinction between these two realms. Instead, he views them as interconnected and mutually constitutive.\n",
      "\n",
      "3. While both philosophers recognize the importance of language in shaping our understanding of reality, they differ in their approach to linguistic analysis. For Plato, words are simply labels that point to pre\n"
     ]
    }
   ],
   "source": [
    "eval_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(model.generate(**model_input, max_new_tokens=256, repetition_penalty=1.15)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3191f05-af49-45d2-a63c-f57a1e45f7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_prompt = \" What are problems with utilitarianism? \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44b1a5ef-7bde-49ea-8475-5a9e18a6ceb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are problems with utilitarianism? 1. It is difficult to compare the value of different pleasures and pains. 2. Utilitarians have no way of deciding how much weight should be given to each person’s happiness.\n",
      "\n",
      "## What are some criticisms of utilitarianism?\n",
      "\n",
      "Criticisms of Utilitarianism:\n",
      "\n",
      "- The greatest good for the greatest number principle does not take into account the rights of individuals.\n",
      "- There is a problem in comparing the value of different pleasures and pains.\n",
      "- There is no way of knowing what the greatest good is.\n",
      "\n",
      "What are the main objections to utilitarianism?\n",
      "\n",
      "The most common objection to utilitarianism is that it fails to give adequate consideration to individual rights, or to the interests of individuals as such. This criticism has been made by many philosophers, including John Stuart Mill (in his essay On Liberty) and G. E. Moore (in Principia Ethica).\n",
      "\n",
      "### Why do people disagree with utilitarianism?\n",
      "\n",
      "Utilitarianism is often criticized because it seems to require us to sacrifice our own well-being for the sake of others. For example, if I am starving but you have enough food to feed both of us\n"
     ]
    }
   ],
   "source": [
    "eval_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(model.generate(**model_input, max_new_tokens=256, repetition_penalty=1.15)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b880349d-1a55-4aa7-9883-094972d7d639",
   "metadata": {},
   "source": [
    "**Preprocessing**: done before setting up LoRA to prepare it for finetuning, done using kit from PEFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "545d7027-9ec8-4a80-bbda-fa54fff27721",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67bf0bc0-839f-42b7-b8ee-a9becd886496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ceb5db-aef0-4725-9ebd-74052caf163d",
   "metadata": {},
   "source": [
    "**Printing Model**: the linear layers that QLoRA will be applied to (q_proj, k_proj, v_proj, o_proj, gate_proj, up_proj, down_proj, and lm_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e05b4cf2-8723-466f-9460-b60d98626096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MistralForCausalLM(\n",
      "  (model): MistralModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x MistralDecoderLayer(\n",
      "        (self_attn): MistralSdpaAttention(\n",
      "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): MistralRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): MistralMLP(\n",
      "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
      "        (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
      "      )\n",
      "    )\n",
      "    (norm): MistralRMSNorm((4096,), eps=1e-05)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdad912-8499-411a-bb25-c64943573939",
   "metadata": {},
   "source": [
    "**LoRA Config**: \n",
    "\n",
    "`r`: rank of the low-rank matrix used in the adapters, which controls number of parameters trained\n",
    "\n",
    "`alpha`: scaling factor for the learned weights; the weight matrix is scaled by `alpha/r`\n",
    "\n",
    "Using `r=32` and `lora_alpha=64` so that we have more emphasis on the new fine-tuned data while also reducing computational complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "163be712-8526-4796-8b2a-d60837f1b413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 85041152 || all params: 3837112320 || trainable%: 2.2162799758751914\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=64,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "        \"lm_head\",\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    lora_dropout=0.05,  # Conventional\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0534ac-02e3-4ef7-bcc9-c9c202616e20",
   "metadata": {},
   "source": [
    "**See New LoRA adaptors!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f3adc8e-dd5b-44af-8808-41272126d705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): MistralForCausalLM(\n",
      "      (model): MistralModel(\n",
      "        (embed_tokens): Embedding(32000, 4096)\n",
      "        (layers): ModuleList(\n",
      "          (0-31): 32 x MistralDecoderLayer(\n",
      "            (self_attn): MistralSdpaAttention(\n",
      "              (q_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (k_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (v_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (o_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (rotary_emb): MistralRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): MistralMLP(\n",
      "              (gate_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=14336, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (up_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=14336, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (down_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=14336, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "            (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
      "            (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (norm): MistralRMSNorm((4096,), eps=1e-05)\n",
      "      )\n",
      "      (lm_head): lora.Linear(\n",
      "        (base_layer): Linear(in_features=4096, out_features=32000, bias=False)\n",
      "        (lora_dropout): ModuleDict(\n",
      "          (default): Dropout(p=0.05, inplace=False)\n",
      "        )\n",
      "        (lora_A): ModuleDict(\n",
      "          (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "        )\n",
      "        (lora_B): ModuleDict(\n",
      "          (default): Linear(in_features=32, out_features=32000, bias=False)\n",
      "        )\n",
      "        (lora_embedding_A): ParameterDict()\n",
      "        (lora_embedding_B): ParameterDict()\n",
      "        (lora_magnitude_vector): ModuleDict()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e21d18-6a4f-4d78-8ab5-20133cfd784c",
   "metadata": {},
   "source": [
    "**Running Training**: used 'max_steps' = 500, because I did not mind overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca7a91b5-06a0-4c78-996a-7200ecf83f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 1: # If more than 1 GPU\n",
    "    model.is_parallelizable = True\n",
    "    model.model_parallel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5fb0267-e149-4d94-a64f-c1e3366d500f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "model = accelerator.prepare_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7dacb577-f2f9-491c-9ef5-cfd0005ee16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbriebi\u001b[0m (\u001b[33mbriebi-university-of-michigan\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/verb-workspace/wandb/run-20240807_223652-6lu59ycx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/briebi-university-of-michigan/journal-finetune/runs/6lu59ycx' target=\"_blank\">mistral-journal-finetune-2024-08-07-22-36</a></strong> to <a href='https://wandb.ai/briebi-university-of-michigan/journal-finetune' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/briebi-university-of-michigan/journal-finetune' target=\"_blank\">https://wandb.ai/briebi-university-of-michigan/journal-finetune</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/briebi-university-of-michigan/journal-finetune/runs/6lu59ycx' target=\"_blank\">https://wandb.ai/briebi-university-of-michigan/journal-finetune/runs/6lu59ycx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 07:49, Epoch 8/9]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.362200</td>\n",
       "      <td>1.491208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.050600</td>\n",
       "      <td>1.402373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.660000</td>\n",
       "      <td>1.268761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.301700</td>\n",
       "      <td>1.339133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>1.255500</td>\n",
       "      <td>1.375633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.697000</td>\n",
       "      <td>1.555402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.736400</td>\n",
       "      <td>1.516231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.472600</td>\n",
       "      <td>2.150999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.338500</td>\n",
       "      <td>1.726974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.326700</td>\n",
       "      <td>1.860854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.239600</td>\n",
       "      <td>2.048797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.218600</td>\n",
       "      <td>1.939124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.184300</td>\n",
       "      <td>2.122133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.169200</td>\n",
       "      <td>2.052248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.173500</td>\n",
       "      <td>2.142975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.141200</td>\n",
       "      <td>2.199553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.140200</td>\n",
       "      <td>2.289889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.136200</td>\n",
       "      <td>2.397927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.132000</td>\n",
       "      <td>2.445627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.131100</td>\n",
       "      <td>2.461421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:204: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:204: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:204: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:204: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:204: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:204: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:204: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:204: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:204: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:204: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:204: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:204: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:204: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:204: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:204: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:204: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:204: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:204: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:204: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:204: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=500, training_loss=0.6433553056716919, metrics={'train_runtime': 471.0874, 'train_samples_per_second': 2.123, 'train_steps_per_second': 1.061, 'total_flos': 4533291786240000.0, 'train_loss': 0.6433553056716919, 'epoch': 8.064516129032258})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "from datetime import datetime\n",
    "\n",
    "project = \"journal-finetune\"\n",
    "base_model_name = \"mistral\"\n",
    "run_name = base_model_name + \"-\" + project\n",
    "output_dir = \"./\" + run_name\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    "    args=transformers.TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        warmup_steps=2,\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=1,\n",
    "        gradient_checkpointing=True,\n",
    "        max_steps=500,\n",
    "        learning_rate=2.5e-5, \n",
    "        bf16=True,\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        logging_steps=25,              \n",
    "        logging_dir=\"./logs\",        \n",
    "        save_strategy=\"steps\",       \n",
    "        save_steps=25,                \n",
    "        evaluation_strategy=\"steps\", \n",
    "        eval_steps=25,               \n",
    "        do_eval=True,                \n",
    "        report_to=\"wandb\",           \n",
    "        run_name=f\"{run_name}-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\"          \n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "\n",
    "model.config.use_cache = False  \n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ede54c6-ecd2-4cea-af2c-c90dcde54778",
   "metadata": {},
   "source": [
    "**Trained Model**: used checkpoint-125; need to reload base model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "246a449e-5a1d-4708-a383-5142f829fbbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c16d4156ad1f497b96558db688ff4277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "base_model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,  # Mistral, same as before\n",
    "    quantization_config=bnb_config,  # Same quantization config as before\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_bos_token=True, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2853fca5-e61c-488c-b996-f4b1b97b8558",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "ft_model = PeftModel.from_pretrained(base_model, \"mistral-journal-finetune/checkpoint-125\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30a8b45-ffae-4adf-974a-29fc6d929f15",
   "metadata": {},
   "source": [
    "**Fine-tuned Model**: testing new model on questions used earlier on base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a99c127b-d4ad-4f40-8d35-5e801dd8a2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How does direction of fit apply to social media?  In other words, how do AI and ML affect the way we use social media?\n",
      " ### Answer: AI and ML are used in social media to predict what you want to see. This makes it easier for people to get stuck in their own filter bubbles because they only see things that confirm their beliefs.\n",
      " What is the difference between a deductively valid argument and an inductively sound argument?\n",
      " ### Answer: A deductively valid argument has true premises and a true conclusion\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = \" How does direction of fit apply to social media? \"\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=100, repetition_penalty=1.15)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b6406d9-40b9-4db3-a34e-b3dddb1e945e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the differences between Gramsci's and Plato's beliefs about reality?  How do these differences affect their views on education?\n",
      " ### Answer: For Gramsci, reality is socially constructed. For Plato, it is objective. Because of this difference, for Gramsci, education should be practical and relevant to students’ lives; for Plato, it should focus on abstract concepts.\n",
      "What does Wittgenstein believe about language?  How does this belief relate to his ideas about AI?\n",
      "### Answer: Language is a social activity that involves shared\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = \" What are the differences between Gramsci's and Plato's beliefs about reality? \"\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=100, repetition_penalty=1.15)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417f36b8-fe7d-4212-b490-3c8d3616981f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_prompt = \" What are problems with utilitarianism \"\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=100, repetition_penalty=1.15)[0], skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
